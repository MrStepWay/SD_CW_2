## Архитектура

Микросервисная архитектура. Полностью соответсвует предложенной в условии схеме, за парой исключений:

1. `File Storage` при запросе на получение файла, возвращает не содержимое файла по id, а сам файл.
2. Получение облака слов производится не по локации, а по id файла, для которого было сгенерировано это облако слов, кажется, что так логичнее и удобнее. Хотя локация тоже возвращается, чтобы соответствовать условию.

### Компоненты системы

1. **API Gateway (`api_gateway`)**
    Это единая точка входа (фасад) для всех внешних клиентов. Он скрывает внутреннюю структуру системы, предоставляя простой и логичный публичный API. Его ключевая задача — оркестрация запросов: он принимает один запрос от пользователя (например, "загрузить и проанализировать файл") и преобразует его в последовательность вызовов к внутренним микросервисам. У него нет собственной базы данных, он stateless.

2. **File Storage Service (`file_storage_service`)**
    Сервис, отвечающий за хранение файлов:
    * Прием файлов (`.txt`).
    * Избегание дублирования файлов с помощью хэша (SHA-256).
    * Хранение метаданных файлов (ID, имя, хэш, путь) в собственной PostgreSQL базе данных.
    * Физическое хранение контента файлов в Docker Volume.
    * Предоставление внутреннего API для получения контента файла по его ID.

3.  **File Analysis Service (`file_analysis_service`)**
    Сервис для анализа файлов:
    * Получение контента файла от `File Storage Service` по внутреннему API.
    * Расчет базовой статистики: количество абзацев, слов, символов.
    * Взаимодействие с внешним API (`quickchart.io`) для генерации изображения облака слов.
    * Кэширование результатов анализа в собственной PostgreSQL базе данных, чтобы избежать повторных вычислений.
    * Предоставление API для получения результатов анализа и сгенерированных изображений.

## Запуск и развертывание

Для запуска проекта необходимы `Docker` и `Docker Compose`.

### Конфигурация

За конфигурацию отвечает файл `.env` в корне проекта, в нём можно указать логины и пароли для баз данных сервисов хранения и анализа (остальное лучше не трогать, но если очень хочется, то можно). `docker-compose.yml` использует эти переменные для настройки контейнеров и для конструирования `DATABASE_URL`, который передается напрямую в каждый сервис.

### Первый запуск

1.  **Сборка и запуск контейнеров.** Команда поднимет все сервисы и базы данных в фоновом режиме.
    ```bash
    docker-compose up --build -d
    ```

2.  **Генерация миграций.** Поскольку это первый запуск, необходимо сгенерировать файлы миграций для каждого сервиса на основе их моделей. Для этого мы используем `docker-compose exec`, чтобы выполнить `alembic` внутри уже работающих контейнеров.
    ```bash
    docker-compose exec file_storage_service alembic revision --autogenerate -m "Initial storage migration"
    docker-compose exec file_analysis_service alembic revision --autogenerate -m "Initial analysis migration"
    ```

3.  **Применение миграций.** После создания миграций, их необходимо применить.
    ```bash
    docker-compose exec file_storage_service alembic upgrade head
    docker-compose exec file_analysis_service alembic upgrade head
    ```

### Последующие запуски

Для обычного запуска достаточно одной команды:
```bash
docker-compose up -d
```
Если вы внесли изменения в модели БД, необходимо сгенерировать новую миграцию (шаг 2) и применить их (шаг 3).

## Спецификация API

Взаимодействие с системой происходит через `API Gateway` по адресу `http://localhost:8000`.

Для демонстрации, пробрешены порты для сервисов хранения и анализа файлов, но вообще это необязательно.

`File Storage Service`: `http://localhost:8001`
`File Analysis Service`: `http://localhost:8002`

У каждого сервиса и API Gateway есть swagger-документация:

`API Gateway`: `http://localhost:8000/docs`
`File Storage Service`: `http://localhost:8001/docs`
`File Analysis Service`: `http://localhost:8002/docs`

---
### Описание API Gateway
### `POST /api/v1/files/`

Загружает текстовый файл, запускает его анализ и немедленно возвращает результат. Это основной и наиболее удобный эндпоинт для пользователя.

*   **Request Body:** `multipart/form-data`
    *   `file`: Файл в формате `.txt`.

*   **Successful Response (201 Created):**
    ```json
    {
      "file_id": "a1b2c3d4-e5f6-7890-1234-56789abcdef0",
      "paragraphs": 5,
      "words": 250,
      "symbols": 1500,
      "word_cloud_location": "/images/wordcloud_a1b2c3d4-e5f6-7890-1234-56789abcdef0.png"
    }
    ```

*   **Error Responses:**
    *   `400 Bad Request`: Если файл не `.txt` или отсутствует.
    *   `503 Service Unavailable`: Если один из внутренних сервисов недоступен.

---

### `GET /api/v1/analysis/{file_id}`

Получает ранее посчитанные результаты анализа для файла.

*   **Path Parameters:**
    *   `file_id` (uuid): Уникальный идентификатор файла.

*   **Successful Response (200 OK):**
    *   Тело ответа идентично успешному ответу `POST /api/v1/files/`.

*   **Error Responses:**
    *   `404 Not Found`: Если анализ для данного `file_id` не найден.

---

### `GET /api/v1/analysis/wordcloud/{file_id}`

Получает сгенерированное изображение облака слов.

*   **Path Parameters:**
    *   `file_id` (uuid): Уникальный идентификатор файла.

*   **Successful Response (200 OK):**
    *   Тело ответа: бинарные данные изображения (`image/png`).

*   **Error Responses:**
    *   `404 Not Found`: Если изображение для данного `file_id` не найдено.

---

### `GET /api/v1/files/{file_id}`

Получает исходное содержимое загруженного текстового файла.

*   **Path Parameters:**
    *   `file_id` (uuid): Уникальный идентификатор файла.

*   **Successful Response (200 OK):**
    *   Тело ответа: бинарные данные файла (`text/plain`).

*   **Error Responses:**
    *   `404 Not Found`: Если файл с таким `file_id` не найден в хранилище.